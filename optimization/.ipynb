{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd import jacobian\n",
    "from numba import jit, float64, int64\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def batch_numba(data, size,seed=663):\n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]\n",
    "    i = np.arange(n)\n",
    "    if n % size !=0:\n",
    "        print(\"The number of observations of data cannot be divided by the input batch size.\")\n",
    "        print('%d data dropped.' % (n%size))\n",
    "        \n",
    "    sample_size = (n // size)*size\n",
    "        \n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(i)\n",
    "    batch_nums = n//size\n",
    "    data = data[i][:sample_size].reshape(size, p, batch_nums)\n",
    "\n",
    "    return(data, batch_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def posi_defnite_check(A):\n",
    "    return np.all(np.linalg.eigvals(A) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(cache = True)\n",
    "\n",
    "def sghmc_numba(gradU, eps, C, Mmatrix, theta_initial, Cov_hat, epoch_nums, epoch_nums_drop, data, size,seed=663):\n",
    "    \n",
    "        ## gradU: function(theta, X, y), U gradient\n",
    "        \n",
    "        ## eps: learning rate\n",
    "        \n",
    "        ## C: friction matrix P X P\n",
    "        \n",
    "        ## Mmatrix: Mass matrix P X P\n",
    "        \n",
    "        ## theta_initial: initial value of theta\n",
    "        \n",
    "        ## Cov_hat: estimated covariance matrix of stochastic gradient noise\n",
    "        \n",
    "        ## epoch_nums: number of epochs to perform\n",
    "        \n",
    "        ## epoch_nums_drop: number of epochs to drop\n",
    "        \n",
    "        ## size: minbatch size per iteration\n",
    "    \n",
    "    random.seed(seed)\n",
    "    n = data.shape[0]\n",
    "    p = theta_initial.shape[0]\n",
    "\n",
    "    theta_samp = np.zeros((p, epoch_nums))\n",
    "    theta_samp[:,0] = theta_initial\n",
    "    \n",
    "    B_hat = 0.5*eps*Cov_hat\n",
    "    \n",
    "    if not posi_defnite_check(2*(C-B_hat)*eps):\n",
    "        print(\"The noise term has to be positive define.\")\n",
    "        return\n",
    "    \n",
    "    noise_sqrt = np.linalg.cholesky(2*(C-B_hat)*eps)\n",
    "    \n",
    "    r = (np.linalg.cholesky(np.linalg.inv(Mmatrix)))@np.random.normal(size = p).reshape(p, -1)\n",
    "    data_batched = batch_numba(data, size)[0]\n",
    "    batch_nums = batch_numba(data, size)[1]\n",
    "    \n",
    "    for i in range(epoch_nums-1):\n",
    "        r = (np.linalg.cholesky(np.linalg.inv(Mmatrix)))@np.random.normal(size = p).reshape(p, -1)\n",
    "        theta = theta_samp[:,i]\n",
    "        \n",
    "        for batch in range(batch_nums):\n",
    "            theta += (eps * Mmatrix @ r).ravel()\n",
    "            gradU_batch = gradU(theta, data_batched[:,:, batch], n, size).reshape(p, -1)\n",
    "            r = r-eps*gradU_batch - eps*C@Mmatrix@r + noise_sqrt@np.random.normal(size = p).reshape(p, -1)\n",
    "        theta_samp[:,i+1] = theta\n",
    "    \n",
    "    return theta_samp[:, epoch_nums_drop:]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([-3,3]).reshape(2,1)\n",
    "\n",
    "def lprior(theta):\n",
    "    return (-1/(2*10))*theta.T@theta\n",
    "\n",
    "def ldatap(theta, x):\n",
    "    return np.log(0.5 * np.exp(-0.5*(theta[0]-x)**2) + 0.5* np.exp(-0.5*(theta[1]-x)**2))\n",
    "\n",
    "def U(theta, x, n, batch_size):\n",
    "    return -lprior(theta) - (n/batch_size)*sum(ldatap(theta, x))\n",
    "\n",
    "gradU = jacobian(U, argnum = 0)\n",
    "\n",
    "@jit\n",
    "def lprior_numba(theta):\n",
    "    return (-1/(2*10))*theta.T@theta\n",
    "\n",
    "@jit\n",
    "def ldatap_numba(theta, x):\n",
    "    return np.log(0.5 * np.exp(-0.5*(theta[0]-x)**2) + 0.5* np.exp(-0.5*(theta[1]-x)**2))\n",
    "\n",
    "@jit\n",
    "def U_numba(theta, x, n, batch_size):\n",
    "    return -lprior_numba(theta) - (n/batch_size)*sum(ldatap_numba(theta, x))\n",
    "\n",
    "gradU_numba = jacobian(U_numba, argnum = 0)\n",
    "\n",
    "#Set up data and parameters\n",
    "np.random.seed(123)\n",
    "n = 100\n",
    "x = np.r_[\n",
    "    np.random.normal(mu[0], 1, n),\n",
    "    np.random.normal(mu[1], 1, n)].reshape(-1,1)\n",
    "\n",
    "theta_0 = np.array([-3, 3]) #start at true value\n",
    "eps = 0.01\n",
    "V_hat = np.eye(2)\n",
    "C = np.eye(2)\n",
    "epochs = 500\n",
    "burns = 200\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.2 s ± 236 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8.45 s ± 276 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sghmc(gradU, eps, C, np.eye(2), theta_0, V_hat, epochs, burns, x, batch_size)\n",
    "%timeit sghmc_numba(gradU, eps, C, np.eye(2), theta_0, V_hat, epochs, burns, x, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
